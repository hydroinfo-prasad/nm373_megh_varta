{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import imutils\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "from tensorflow.keras.layers import Input, Dense, MaxPooling2D, MaxPooling3D, Dropout, BatchNormalization, Flatten, Conv2D, Conv3D, AveragePooling3D, LSTM, Reshape\n",
    "\n",
    "from keras.layers.convolutional_recurrent import ConvLSTM2D\n",
    "\n",
    "import cv2\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Dense, Flatten, UpSampling2D\n",
    "#from keras import backend as K\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib.pyplot import imshow, figure\n",
    "\n",
    "from tensorflow.keras.layers import Lambda, Reshape, Permute, Input, add, Conv3D\n",
    "from tensorflow.keras.models import Model\n",
    "import os\n",
    "from tensorflow.keras.callbacks import History \n",
    "\n",
    "#print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pre_process import Preprocessed_additional_data\n",
    "from pre_process import Preprocessed_1day_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path='/home/prasad/pytorch-unet/INSAT3D_VIS_India/'\n",
    "\n",
    "\n",
    "X,y,verify=Preprocessed_1day_data(normalization_type='scaling',\n",
    "                                  dir_path=dir_path,\n",
    "                                  inp_seq_len=3,pred_frame=1,normalized_output='no')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,Y=shuffle(X,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Xind=26\n",
    "X_train=X[:ind]\n",
    "y_train=y[:ind]\n",
    "X_val=X[ind:]\n",
    "y_val=y[ind:]\n",
    "\n",
    "(X_train.shape),y_train.shape,X_val.shape,y_val.shape\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_lst_m2d_1 (ConvLSTM2D)  (None, 984, 1074, 40)     164160    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 984, 1074, 40)     160       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 984, 1074, 10)     10010     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 984, 1074, 10)     40        \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 984, 1074, 5)      1255      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 984, 1074, 5)      20        \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 984, 1074, 1)      46        \n",
      "=================================================================\n",
      "Total params: 175,691\n",
      "Trainable params: 175,581\n",
      "Non-trainable params: 110\n",
      "_________________________________________________________________\n",
      "None\n",
      "len of X and y: 36 36\n"
     ]
    }
   ],
   "source": [
    "\n",
    "height, width=x.shape[2], x.shape[3]   #model.save('conv_h984_w3_4_loss_1443.h5') model.save('conv_h984_w3_9_additionald_2_loss_tr1224_v651.h5')\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(\n",
    "            shape=(None, height, width, 1)\n",
    "        ),  # Variable-length sequence of 40x40x1 frames\n",
    "        layers.ConvLSTM2D(\n",
    "            filters=40, kernel_size=(5,5), padding=\"same\", return_sequences=False\n",
    "        ),\n",
    "        \n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(\n",
    "            filters=10, kernel_size=(5,5), padding=\"same\"\n",
    "        ),\n",
    "        \n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(\n",
    "            filters=5, kernel_size=(5,5), padding=\"same\"\n",
    "        ),\n",
    "        \n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(\n",
    "            filters=1, kernel_size=(3,3), padding=\"same\"\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(model.summary())\n",
    "#print(model.summary())\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "earlystop = EarlyStopping(\n",
    "                          monitor='loss',\n",
    "                          min_delta=0,\n",
    "                          patience=4,\n",
    "                          verbose=1,restore_best_weights=True)\n",
    "\n",
    "callbacks = [earlystop]\n",
    "print('len of X and y:',len(X), len(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((36, 3, 984, 1074, 1), (36, 984, 1074, 1))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape,Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "28/28 [==============================] - 24s 873ms/step - loss: 8920.4951 - val_loss: 4626.4268\n",
      "Epoch 2/150\n",
      "28/28 [==============================] - 25s 877ms/step - loss: 8816.2939 - val_loss: 4542.0015\n",
      "Epoch 3/150\n",
      "28/28 [==============================] - 25s 892ms/step - loss: 8725.4404 - val_loss: 4428.6025\n",
      "Epoch 4/150\n",
      "28/28 [==============================] - 25s 902ms/step - loss: 8620.1387 - val_loss: 4353.0352\n",
      "Epoch 5/150\n",
      "28/28 [==============================] - 25s 910ms/step - loss: 8500.3799 - val_loss: 4304.3213\n",
      "Epoch 6/150\n",
      "28/28 [==============================] - 26s 917ms/step - loss: 8371.4541 - val_loss: 4206.9644\n",
      "Epoch 7/150\n",
      "28/28 [==============================] - 26s 922ms/step - loss: 8233.8193 - val_loss: 4207.2642\n",
      "Epoch 8/150\n",
      "28/28 [==============================] - 26s 928ms/step - loss: 8076.6304 - val_loss: 4157.8545\n",
      "Epoch 9/150\n",
      "28/28 [==============================] - 26s 933ms/step - loss: 7915.6240 - val_loss: 4120.3862\n",
      "Epoch 10/150\n",
      "28/28 [==============================] - 26s 936ms/step - loss: 7742.2686 - val_loss: 4070.2856\n",
      "Epoch 11/150\n",
      "28/28 [==============================] - 26s 939ms/step - loss: 7561.3350 - val_loss: 3743.1399\n",
      "Epoch 12/150\n",
      "28/28 [==============================] - 26s 940ms/step - loss: 7380.4990 - val_loss: 3787.0210\n",
      "Epoch 13/150\n",
      "28/28 [==============================] - 26s 942ms/step - loss: 7184.2876 - val_loss: 3957.0684\n",
      "Epoch 14/150\n",
      "28/28 [==============================] - 26s 942ms/step - loss: 7074.0635 - val_loss: 1188.0378\n",
      "Epoch 15/150\n",
      "28/28 [==============================] - 26s 943ms/step - loss: 6888.7290 - val_loss: 2728.4031\n",
      "Epoch 16/150\n",
      "28/28 [==============================] - 26s 944ms/step - loss: 6651.3765 - val_loss: 2723.3247\n",
      "Epoch 17/150\n",
      "28/28 [==============================] - 26s 943ms/step - loss: 6432.2539 - val_loss: 2839.9583\n",
      "Epoch 18/150\n",
      "28/28 [==============================] - 26s 943ms/step - loss: 6228.4883 - val_loss: 2932.3320\n",
      "Epoch 19/150\n",
      "28/28 [==============================] - 26s 941ms/step - loss: 6007.8008 - val_loss: 2372.2085\n",
      "Epoch 20/150\n",
      "28/28 [==============================] - 26s 941ms/step - loss: 5833.2788 - val_loss: 2866.3420\n",
      "Epoch 21/150\n",
      "28/28 [==============================] - 26s 940ms/step - loss: 5624.9702 - val_loss: 3044.6523\n",
      "Epoch 22/150\n",
      "28/28 [==============================] - 26s 940ms/step - loss: 5434.8359 - val_loss: 4400.3184\n",
      "Epoch 23/150\n",
      "28/28 [==============================] - 26s 940ms/step - loss: 5240.5107 - val_loss: 2666.7776\n",
      "Epoch 24/150\n",
      "28/28 [==============================] - 26s 937ms/step - loss: 5062.3540 - val_loss: 4630.7559\n",
      "Epoch 25/150\n",
      "28/28 [==============================] - 26s 937ms/step - loss: 4871.9219 - val_loss: 3704.6396\n",
      "Epoch 26/150\n",
      "28/28 [==============================] - 26s 935ms/step - loss: 4705.8281 - val_loss: 3267.4023\n",
      "Epoch 27/150\n",
      "28/28 [==============================] - 26s 936ms/step - loss: 4557.9873 - val_loss: 4823.7974\n",
      "Epoch 28/150\n",
      "28/28 [==============================] - 26s 936ms/step - loss: 4425.7661 - val_loss: 7365.9810\n",
      "Epoch 29/150\n",
      "28/28 [==============================] - 26s 936ms/step - loss: 4357.3198 - val_loss: 335.8429\n",
      "Epoch 30/150\n",
      "28/28 [==============================] - 26s 937ms/step - loss: 4148.6777 - val_loss: 3302.1104\n",
      "Epoch 31/150\n",
      "28/28 [==============================] - 26s 937ms/step - loss: 3972.9739 - val_loss: 4021.8892\n",
      "Epoch 32/150\n",
      "28/28 [==============================] - 26s 937ms/step - loss: 3855.4839 - val_loss: 2718.2534\n",
      "Epoch 33/150\n",
      "28/28 [==============================] - 26s 937ms/step - loss: 3752.9497 - val_loss: 1878.1611\n",
      "Epoch 34/150\n",
      "28/28 [==============================] - 26s 937ms/step - loss: 3620.6038 - val_loss: 2849.2959\n",
      "Epoch 35/150\n",
      "28/28 [==============================] - 26s 938ms/step - loss: 3515.7278 - val_loss: 1591.3682\n",
      "Epoch 36/150\n",
      "28/28 [==============================] - 26s 936ms/step - loss: 3440.4978 - val_loss: 1472.6893\n",
      "Epoch 37/150\n",
      "28/28 [==============================] - 26s 932ms/step - loss: 3328.2131 - val_loss: 2451.4304\n",
      "Epoch 38/150\n",
      "28/28 [==============================] - 26s 935ms/step - loss: 3274.3308 - val_loss: 3376.0742\n",
      "Epoch 39/150\n",
      "28/28 [==============================] - 26s 936ms/step - loss: 3188.3179 - val_loss: 4981.8877\n",
      "Epoch 40/150\n",
      "28/28 [==============================] - 26s 936ms/step - loss: 3124.7461 - val_loss: 1958.1340\n",
      "Epoch 41/150\n",
      "28/28 [==============================] - 26s 936ms/step - loss: 3038.3965 - val_loss: 1546.6462\n",
      "Epoch 42/150\n",
      "28/28 [==============================] - 26s 935ms/step - loss: 2977.9966 - val_loss: 1053.6171\n",
      "Epoch 43/150\n",
      "28/28 [==============================] - 26s 936ms/step - loss: 2941.9338 - val_loss: 345.9691\n",
      "Epoch 44/150\n",
      "28/28 [==============================] - 26s 936ms/step - loss: 2894.9456 - val_loss: 928.4423\n",
      "Epoch 45/150\n",
      "28/28 [==============================] - 26s 936ms/step - loss: 2833.0598 - val_loss: 611.6690\n",
      "Epoch 46/150\n",
      "28/28 [==============================] - 26s 933ms/step - loss: 2849.6582 - val_loss: 872.0120\n",
      "Epoch 47/150\n",
      "28/28 [==============================] - 26s 934ms/step - loss: 2854.5356 - val_loss: 312.0232\n",
      "Epoch 48/150\n",
      "28/28 [==============================] - 26s 936ms/step - loss: 2789.7292 - val_loss: 2382.5513\n",
      "Epoch 49/150\n",
      "28/28 [==============================] - 26s 936ms/step - loss: 2706.9575 - val_loss: 1481.6816\n",
      "Epoch 50/150\n",
      "28/28 [==============================] - 26s 937ms/step - loss: 2684.8503 - val_loss: 643.2230\n",
      "Epoch 51/150\n",
      "28/28 [==============================] - 26s 938ms/step - loss: 2649.1653 - val_loss: 1380.1930\n",
      "Epoch 52/150\n",
      "28/28 [==============================] - 26s 936ms/step - loss: 2646.1150 - val_loss: 458.2041\n",
      "Epoch 53/150\n",
      "28/28 [==============================] - 26s 936ms/step - loss: 2616.9983 - val_loss: 571.3613\n",
      "Epoch 54/150\n",
      "28/28 [==============================] - 26s 935ms/step - loss: 2606.1733 - val_loss: 997.4709\n",
      "Epoch 55/150\n",
      "28/28 [==============================] - 26s 934ms/step - loss: 2580.5020 - val_loss: 398.1370\n",
      "Epoch 56/150\n",
      "28/28 [==============================] - 26s 934ms/step - loss: 2562.2983 - val_loss: 632.8873\n",
      "Epoch 57/150\n",
      "28/28 [==============================] - 26s 937ms/step - loss: 2562.3501 - val_loss: 737.0469\n",
      "Epoch 58/150\n",
      "28/28 [==============================] - 26s 937ms/step - loss: 2541.6694 - val_loss: 391.7266\n",
      "Epoch 59/150\n",
      "28/28 [==============================] - 26s 935ms/step - loss: 2526.8281 - val_loss: 392.1429\n",
      "Epoch 60/150\n",
      "28/28 [==============================] - 26s 936ms/step - loss: 2525.0532 - val_loss: 353.9256\n",
      "Epoch 61/150\n",
      "28/28 [==============================] - 26s 936ms/step - loss: 2524.8743 - val_loss: 320.7736\n",
      "Epoch 62/150\n",
      "28/28 [==============================] - 26s 934ms/step - loss: 2511.8494 - val_loss: 311.7696\n",
      "Epoch 63/150\n",
      "28/28 [==============================] - 26s 933ms/step - loss: 2512.7129 - val_loss: 366.7156\n",
      "Epoch 64/150\n",
      "28/28 [==============================] - 26s 935ms/step - loss: 2503.1477 - val_loss: 465.9417\n",
      "Epoch 65/150\n",
      "28/28 [==============================] - 26s 935ms/step - loss: 2493.8669 - val_loss: 307.7811\n",
      "Epoch 66/150\n",
      "28/28 [==============================] - 26s 937ms/step - loss: 2514.6213 - val_loss: 546.2701\n",
      "Epoch 67/150\n",
      "28/28 [==============================] - 26s 936ms/step - loss: 2498.2971 - val_loss: 667.0024\n",
      "Epoch 68/150\n",
      "28/28 [==============================] - 26s 935ms/step - loss: 2493.5652 - val_loss: 434.9429\n",
      "Epoch 69/150\n",
      "28/28 [==============================] - 26s 937ms/step - loss: 2523.4871 - val_loss: 2364.9221\n",
      "Epoch 70/150\n",
      "28/28 [==============================] - 26s 936ms/step - loss: 2562.9451 - val_loss: 453.3557\n",
      "Epoch 71/150\n",
      "28/28 [==============================] - 26s 936ms/step - loss: 2506.4163 - val_loss: 299.7781\n",
      "Epoch 72/150\n",
      "28/28 [==============================] - 26s 935ms/step - loss: 2487.7932 - val_loss: 301.7050\n",
      "Epoch 73/150\n",
      "28/28 [==============================] - 26s 937ms/step - loss: 2494.3015 - val_loss: 349.7501\n",
      "Epoch 74/150\n",
      "28/28 [==============================] - 26s 936ms/step - loss: 2577.3691 - val_loss: 353.5780\n",
      "Epoch 75/150\n",
      "28/28 [==============================] - 26s 936ms/step - loss: 2481.2224 - val_loss: 390.3529\n",
      "Epoch 76/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 26s 936ms/step - loss: 2471.6340 - val_loss: 385.1139\n",
      "Epoch 77/150\n",
      "28/28 [==============================] - 26s 934ms/step - loss: 2466.1382 - val_loss: 395.6442\n",
      "Epoch 78/150\n",
      "28/28 [==============================] - 26s 931ms/step - loss: 2465.0098 - val_loss: 420.3785\n",
      "Epoch 79/150\n",
      "28/28 [==============================] - 26s 934ms/step - loss: 2460.9631 - val_loss: 334.1341\n",
      "Epoch 80/150\n",
      "28/28 [==============================] - 26s 936ms/step - loss: 2461.9407 - val_loss: 368.4435\n",
      "Epoch 81/150\n",
      "28/28 [==============================] - 26s 934ms/step - loss: 2458.9590 - val_loss: 367.6859\n",
      "Epoch 82/150\n",
      "28/28 [==============================] - 26s 934ms/step - loss: 2459.7817 - val_loss: 437.8792\n",
      "Epoch 83/150\n",
      "28/28 [==============================] - 26s 935ms/step - loss: 2470.5757 - val_loss: 302.6378\n",
      "Epoch 84/150\n",
      "28/28 [==============================] - 26s 937ms/step - loss: 2455.9563 - val_loss: 357.6398\n",
      "Epoch 85/150\n",
      "28/28 [==============================] - 26s 937ms/step - loss: 2455.4058 - val_loss: 372.3343\n",
      "Epoch 86/150\n",
      "28/28 [==============================] - 26s 936ms/step - loss: 2457.0054 - val_loss: 320.3693\n",
      "Epoch 87/150\n",
      "28/28 [==============================] - 26s 936ms/step - loss: 2459.5979 - val_loss: 379.5044\n",
      "Epoch 88/150\n",
      "28/28 [==============================] - 26s 936ms/step - loss: 2542.0156 - val_loss: 345.0023\n",
      "Epoch 89/150\n",
      "28/28 [==============================] - ETA: 0s - loss: 2507.9719Restoring model weights from the end of the best epoch.\n",
      "28/28 [==============================] - 26s 936ms/step - loss: 2507.9719 - val_loss: 903.7891\n",
      "Epoch 00089: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7eff202154a8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x,Y ,batch_size=1,epochs=150,callbacks=callbacks,validation_split=0.2,shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('visconv_h984_w3_1_loss_345.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "28/28 [==============================] - 24s 860ms/step - loss: 2458.5933 - val_loss: 335.5433\n",
      "Epoch 2/150\n",
      "28/28 [==============================] - 24s 869ms/step - loss: 2468.7346 - val_loss: 369.8192\n",
      "Epoch 3/150\n",
      "28/28 [==============================] - 25s 885ms/step - loss: 2454.3560 - val_loss: 331.0042\n",
      "Epoch 4/150\n",
      "28/28 [==============================] - 25s 897ms/step - loss: 2452.9534 - val_loss: 352.5526\n",
      "Epoch 5/150\n",
      "28/28 [==============================] - 25s 904ms/step - loss: 2458.3879 - val_loss: 612.4657\n",
      "Epoch 6/150\n",
      "28/28 [==============================] - 26s 911ms/step - loss: 2462.9651 - val_loss: 283.3830\n",
      "Epoch 7/150\n",
      "28/28 [==============================] - 26s 919ms/step - loss: 2457.4539 - val_loss: 300.2727\n",
      "Epoch 8/150\n",
      "28/28 [==============================] - ETA: 0s - loss: 2460.0935Restoring model weights from the end of the best epoch.\n",
      "28/28 [==============================] - 26s 922ms/step - loss: 2460.0935 - val_loss: 367.2411\n",
      "Epoch 00008: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f001954f550>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x,Y ,batch_size=1,epochs=150,callbacks=callbacks,validation_split=0.2,shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('visconv_h984_w3_2extdtr_loss_345.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0d105228384a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m   \u001b[0;31m#model.save('conv_h984_w3_4_loss_1443.h5') model.save('conv_h984_w3_9_additionald_2_loss_tr1224_v651.h5')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m model = keras.Sequential(\n\u001b[1;32m      3\u001b[0m     [\n\u001b[1;32m      4\u001b[0m         keras.Input(\n\u001b[1;32m      5\u001b[0m             \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "height, width=x.shape[2], x.shape[3]   #model.save('conv_h984_w3_4_loss_1443.h5') model.save('conv_h984_w3_9_additionald_2_loss_tr1224_v651.h5')\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(\n",
    "            shape=(None, height, width, 1)\n",
    "        ),  # Variable-length sequence of 40x40x1 frames\n",
    "        layers.ConvLSTM2D(\n",
    "            filters=40, kernel_size=(5,5), padding=\"same\", return_sequences=False\n",
    "        ),\n",
    "        \n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(\n",
    "            filters=15, kernel_size=(5,5), padding=\"same\"\n",
    "        ),\n",
    "        \n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(\n",
    "            filters=10, kernel_size=(5,5), padding=\"same\"\n",
    "        ),\n",
    "        \n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(\n",
    "            filters=1, kernel_size=(3,3), padding=\"same\"\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(model.summary())\n",
    "#print(model.summary())\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "earlystop = EarlyStopping(\n",
    "                          monitor='loss',\n",
    "                          min_delta=0,\n",
    "                          patience=4,\n",
    "                          verbose=1,restore_best_weights=True)\n",
    "\n",
    "callbacks = [earlystop]\n",
    "print('len of X and y:',len(X), len(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([234]),)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#path = \"/home/prasad/SIH/oct/tir/\"  \n",
    "path = \"/home/prasad/SIH/oct/vis/\"\n",
    "Oct = os.listdir( path )\n",
    "Oct=sorted(Oct)\n",
    "\n",
    "#path2 = \"/home/prasad/SIH/nov_2019_data/tir/\"\n",
    "path2 = \"/home/prasad/SIH/nov_2019_data/vis/\"\n",
    "Nov = os.listdir( path2 )\n",
    "Nov=sorted(Nov)\n",
    "\n",
    "Oct = [ elem for elem in Oct if int(elem[18:20]) % 30 == 0] \n",
    "Nov     = [ elem for elem in Nov if int(elem[18:20]) % 30 == 0] \n",
    "Nov=np.array(Nov)\n",
    "Oct= np.array(Oct)\n",
    "\n",
    "End_index=np.where(Nov=='3DIMG_06NOV2019_2300_L1C_SGP_IMG_VIS.tif')\n",
    "End_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['3DIMG_01NOV2019_0000_L1C_SGP_IMG_VIS.tif',\n",
       "       '3DIMG_01NOV2019_0030_L1C_SGP_IMG_VIS.tif',\n",
       "       '3DIMG_01NOV2019_0100_L1C_SGP_IMG_VIS.tif', ...,\n",
       "       '3DIMG_30NOV2019_2230_L1C_SGP_IMG_VIS.tif',\n",
       "       '3DIMG_30NOV2019_2300_L1C_SGP_IMG_VIS.tif',\n",
       "       '3DIMG_30NOV2019_2330_L1C_SGP_IMG_VIS.tif'], dtype='<U40')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Nov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading images\n",
      "50 images out of 1274 are loaded\n",
      "100 images out of 1274 are loaded\n",
      "150 images out of 1274 are loaded\n",
      "200 images out of 1274 are loaded\n",
      "250 images out of 1274 are loaded\n",
      "300 images out of 1274 are loaded\n",
      "350 images out of 1274 are loaded\n",
      "400 images out of 1274 are loaded\n",
      "450 images out of 1274 are loaded\n",
      "500 images out of 1274 are loaded\n",
      "550 images out of 1274 are loaded\n",
      "600 images out of 1274 are loaded\n",
      "650 images out of 1274 are loaded\n",
      "700 images out of 1274 are loaded\n",
      "750 images out of 1274 are loaded\n",
      "800 images out of 1274 are loaded\n",
      "850 images out of 1274 are loaded\n",
      "900 images out of 1274 are loaded\n",
      "950 images out of 1274 are loaded\n",
      "1000 images out of 1274 are loaded\n",
      "1050 images out of 1274 are loaded\n",
      "1100 images out of 1274 are loaded\n",
      "1150 images out of 1274 are loaded\n",
      "1200 images out of 1274 are loaded\n",
      "1250 images out of 1274 are loaded\n",
      "normalizing images\n",
      "50 images out of 1274 are normalized\n",
      "100 images out of 1274 are normalized\n",
      "150 images out of 1274 are normalized\n",
      "200 images out of 1274 are normalized\n",
      "250 images out of 1274 are normalized\n",
      "300 images out of 1274 are normalized\n",
      "350 images out of 1274 are normalized\n",
      "400 images out of 1274 are normalized\n",
      "450 images out of 1274 are normalized\n",
      "500 images out of 1274 are normalized\n",
      "550 images out of 1274 are normalized\n",
      "600 images out of 1274 are normalized\n",
      "650 images out of 1274 are normalized\n",
      "700 images out of 1274 are normalized\n",
      "750 images out of 1274 are normalized\n",
      "800 images out of 1274 are normalized\n",
      "850 images out of 1274 are normalized\n",
      "900 images out of 1274 are normalized\n",
      "950 images out of 1274 are normalized\n",
      "1000 images out of 1274 are normalized\n",
      "1050 images out of 1274 are normalized\n",
      "1100 images out of 1274 are normalized\n",
      "1150 images out of 1274 are normalized\n",
      "1200 images out of 1274 are normalized\n",
      "1250 images out of 1274 are normalized\n",
      "making images sequences with length: 3\n",
      "50 images out of 1274 are processed\n",
      "100 images out of 1274 are processed\n",
      "150 images out of 1274 are processed\n",
      "200 images out of 1274 are processed\n",
      "250 images out of 1274 are processed\n",
      "300 images out of 1274 are processed\n",
      "350 images out of 1274 are processed\n",
      "400 images out of 1274 are processed\n",
      "450 images out of 1274 are processed\n",
      "500 images out of 1274 are processed\n",
      "550 images out of 1274 are processed\n",
      "600 images out of 1274 are processed\n",
      "650 images out of 1274 are processed\n",
      "700 images out of 1274 are processed\n",
      "750 images out of 1274 are processed\n",
      "800 images out of 1274 are processed\n",
      "850 images out of 1274 are processed\n",
      "900 images out of 1274 are processed\n",
      "950 images out of 1274 are processed\n",
      "1000 images out of 1274 are processed\n",
      "1050 images out of 1274 are processed\n",
      "1100 images out of 1274 are processed\n",
      "1150 images out of 1274 are processed\n",
      "1200 images out of 1274 are processed\n",
      "1250 images out of 1274 are processed\n"
     ]
    }
   ],
   "source": [
    "X_train,y_train,X_val,y_val,maxx,minn,verify=  Preprocessed_additional_data(normalization_type='scaling',path=path,start_img_path=Oct[0], end_img_path=Oct[-1],inp_seq_len=3,pred_frame=1,normalized_output='no',Validation_split=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=np.reshape(X_train, (X_train.shape[0],X_train.shape[1],X_train.shape[2],X_train.shape[3],1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1136, 3, 984, 1074)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93.6"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Nov[:End_index[0][0]])-len(Nov[:End_index[0][0]])*0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "234"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Nov[:End_index[0][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64),)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "End_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading images\n",
      "50 images out of 235 are loaded\n",
      "100 images out of 235 are loaded\n",
      "150 images out of 235 are loaded\n",
      "200 images out of 235 are loaded\n",
      "normalizing images\n",
      "50 images out of 235 are normalized\n",
      "100 images out of 235 are normalized\n",
      "150 images out of 235 are normalized\n",
      "200 images out of 235 are normalized\n",
      "making images sequences with length: 3\n",
      "50 images out of 235 are processed\n",
      "100 images out of 235 are processed\n",
      "150 images out of 235 are processed\n",
      "200 images out of 235 are processed\n"
     ]
    }
   ],
   "source": [
    "X_train1,y_train1,X_val1,y_val1,maxx1,minn1,verify1=  Preprocessed_additional_data(normalization_type='scaling',path=path2, start_img_path=Nov[0], end_img_path=Nov[End_index[0][0]],inp_seq_len=3,pred_frame=1,normalized_output='no',Validation_split=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1=np.reshape(X_train1, (X_train1.shape[0],X_train1.shape[1],X_train1.shape[2],X_train1.shape[3],1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=np.concatenate((X_train,X_train1), axis=0)\n",
    "y_train=np.concatenate((y_train,y_train1), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_lst_m2d (ConvLSTM2D)    (None, 984, 1074, 40)     164160    \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 984, 1074, 40)     160       \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 984, 1074, 10)     10010     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 984, 1074, 10)     40        \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 984, 1074, 5)      1255      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 984, 1074, 5)      20        \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 984, 1074, 1)      46        \n",
      "=================================================================\n",
      "Total params: 175,691\n",
      "Trainable params: 175,581\n",
      "Non-trainable params: 110\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-03cd18e9a854>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mearlystop\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'len of X and y:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "height, width=X_train.shape[2], X_train.shape[3]   #model.save('conv_h984_w3_4_loss_1443.h5') model.save('conv_h984_w3_9_additionald_2_loss_tr1224_v651.h5')\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(\n",
    "            shape=(None, height, width, 1)\n",
    "        ),  # Variable-length sequence of 40x40x1 frames\n",
    "        layers.ConvLSTM2D(\n",
    "            filters=40, kernel_size=(5,5), padding=\"same\", return_sequences=False\n",
    "        ),\n",
    "        \n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(\n",
    "            filters=10, kernel_size=(5,5), padding=\"same\"\n",
    "        ),\n",
    "        \n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(\n",
    "            filters=5, kernel_size=(5,5), padding=\"same\"\n",
    "        ),\n",
    "        \n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(\n",
    "            filters=1, kernel_size=(3,3), padding=\"same\"\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(model.summary())\n",
    "#print(model.summary())\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "earlystop = EarlyStopping(\n",
    "                          monitor='loss',\n",
    "                          min_delta=0,\n",
    "                          patience=4,\n",
    "                          verbose=1,restore_best_weights=True)\n",
    "\n",
    "callbacks = [earlystop]\n",
    "print('len of X and y:',len(X), len(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "earlystop = EarlyStopping(\n",
    "                          monitor='loss',\n",
    "                          min_delta=0,\n",
    "                          patience=2,\n",
    "                          verbose=1,restore_best_weights=True)\n",
    "\n",
    "callbacks = [earlystop]\n",
    "print('len of X and y:',len(X), len(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train,y_train,batch_size=1,epochs=150,callbacks=callbacks,validation_split=0.2,shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "Max=max(maxx,maxx1)\n",
    "Min=min(minn,minn1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val1.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=np.concatenate((X_train,X_train1), axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(X_train,Type='scaling',Max=0,Min=0,mean=0,std_dev=0):\n",
    "    X=X_train\n",
    "    seq_len=X.shape[1]\n",
    "    samples=X.shape[0]\n",
    "    for i in range(samples):\n",
    "        for j in range(seq_len):\n",
    "            if Type=='scaling':\n",
    "                X[i][j]=((X[i][j])-Min)/(Max-Min)\n",
    "            else:\n",
    "                X[i][j] = ((X[i][j] - mean)/std_dev)\n",
    "            \n",
    "    return(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization(X_train,Type='scaling',Max=0,Min=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
